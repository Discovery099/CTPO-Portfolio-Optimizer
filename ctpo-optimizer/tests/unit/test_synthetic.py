"""\nSynthetic scenario tests with known solutions\n"""\n\nimport pytest\nimport numpy as np\nimport sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent.parent.parent))\n\nfrom ctpo.core.optimizer import CTPOOptimizer\n\n@pytest.mark.unit\nclass TestSyntheticScenarios:\n    \"\"\"Tests using synthetic data\"\"\"\n    \n    def test_equal_risk_portfolio(self):\n        \"\"\"Test with equal-volatility uncorrelated assets\"\"\"\n        np.random.seed(42)\n        n = 10\n        n_periods = 252\n        \n        # Create equal-volatility assets\n        returns = np.random.normal(0.0005, 0.02, (n_periods, n))\n        \n        optimizer = CTPOOptimizer()\n        weights = optimizer.optimize(returns)\n        \n        # Should have relatively uniform distribution\n        weight_std = np.std(weights)\n        assert weight_std < 0.15, \\\n            f\"Equal risk assets should yield more uniform weights (std={weight_std:.3f})\"\n    \n    def test_dominant_asset(self):\n        \"\"\"Test with one clearly superior asset\"\"\"\n        np.random.seed(42)\n        n = 10\n        n_periods = 252\n        \n        # Create returns with one dominant asset\n        returns = np.random.normal(0.0003, 0.02, (n_periods, n))\n        returns[:, 0] = np.random.normal(0.002, 0.02, n_periods)  # 5x higher return\n        \n        optimizer = CTPOOptimizer()\n        weights = optimizer.optimize(returns)\n        \n        # Dominant asset should have highest weight\n        assert weights[0] == np.max(weights), \\\n            \"Dominant asset should have maximum weight\"\n        \n        # Should still maintain diversification due to constraints\n        enp = 1.0 / np.sum(weights ** 2)\n        assert enp >= 2.0, \\\n            \"Should maintain minimum diversification\"\n    \n    def test_high_correlation_stress(self):\n        \"\"\"Test behavior under high correlation\"\"\"\n        np.random.seed(42)\n        n = 10\n        n_periods = 252\n        \n        # Create highly correlated returns\n        base = np.random.normal(0.0005, 0.03, n_periods)\n        returns = np.column_stack([\n            base + np.random.normal(0, 0.005, n_periods)\n            for _ in range(n)\n        ])\n        \n        optimizer = CTPOOptimizer()\n        weights = optimizer.optimize(returns)\n        \n        # Should still diversify despite correlation\n        enp = 1.0 / np.sum(weights ** 2)\n        assert enp >= 3.0, \\\n            f\"High correlation should force diversification (ENP={enp:.2f})\"\n    \n    def test_parameter_continuity(self):\n        \"\"\"Test that small parameter changes yield smooth weight changes\"\"\"\n        np.random.seed(42)\n        n = 10\n        n_periods = 252\n        \n        returns1 = np.random.normal(0.0005, 0.02, (n_periods, n))\n        returns2 = returns1 * 1.01  # 1% change\n        \n        optimizer = CTPOOptimizer()\n        \n        weights1 = optimizer.optimize(returns1)\n        weights2 = optimizer.optimize(returns2)\n        \n        # Weights should be similar\n        weight_change = np.linalg.norm(weights2 - weights1)\n        assert weight_change < 0.1, \\\n            f\"Large weight change {weight_change:.3f} from small data change\"\n\n\nif __name__ == '__main__':\n    pytest.main([__file__, '-v'])\n